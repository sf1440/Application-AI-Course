{"cells":[{"cell_type":"markdown","metadata":{"id":"CdL1ZvDepO-X"},"source":["<a href=\"https://colab.research.google.com/github/jeffheaton/app_generative_ai/blob/main/assignments/assignment_yourname_t81_559_class4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"R_pemiL8pO-Y"},"source":["# T81-559: Applications of Generative AI\n","* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/index.html)\n","* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-559/).\n","\n","**Module 4 Assignment: Chat Memory**\n","\n","**Student Name: Your Name**"]},{"cell_type":"markdown","metadata":{"id":"lky4xopspO-Z"},"source":["# Assignment Instructions\n","\n","A [file](https://data.heatonresearch.com/data/t81-559/assignments/transcript4.csv) is provided that contains a transcript with two chatbots. Responses should always be a single sentence. The file is shown here:\n","\n","|target|prompt|\n","|--|--|\n","|chat1|Hello my name is John.|\n","|chat2|Hello my name is Jane|\n","|chat1|My favorite color is blue.|\n","|chat2|My favorite color is yellow.|\n","|chat1|What is my name and favorite color.|\n","|chat2|What is my name?|\n","\n","Write a program that creates two chatbots, each should have their own memory. Send these transcript items to the indicated chatbot and record their responses in your output file.\n","\n","Your output should look like something this:\n","\n","|target|response|\n","|--|--|\n","|chat1|Hi John.|\n","|chat2|Hello Jane.|\n","|chat1|Thank you for this information.|\n","|chat2|Thank you for this information.|\n","|chat1|Hi John, your name is John and your favorite color is blue.|\n","|chat2|Hey Jane, your name is Jane.|\n","\n","Note that the LLM will not give this exact output, but it should be similar.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U4LQZW_SpO-Z"},"source":["# Google CoLab Instructions\n","\n","If you are using Google CoLab, it will be necessary to mount your GDrive so that you can send your notebook during the submit process. Running the following code will map your GDrive to ```/content/drive```."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"1ZnCEIEopO-Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739235724838,"user_tz":360,"elapsed":7495,"user":{"displayName":"Luv Letter","userId":"00690244338853962621"}},"outputId":"35a3db66-3afa-432a-b1b8-9a4eb25cddea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Note: using Google CoLab\n","Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.17)\n","Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.4)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.34)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n","Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n","Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n","Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.61.1)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.8.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain_openai) (4.67.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain) (3.0.0)\n"]}],"source":["import os\n","\n","try:\n","  from google.colab import drive, userdata\n","  drive.mount('/content/drive', force_remount=True)\n","  COLAB = True\n","  print(\"Note: using Google CoLab\")\n","except:\n","  print(\"Note: not using Google CoLab\")\n","  COLAB = False\n","\n","# Assignment Submission Key - Was sent you first week of class.\n","# If you are in both classes, this is the same key.\n","if COLAB:\n","  # For Colab, add to your \"Secrets\" (key icon at the left)\n","  key = userdata.get('T81_559_KEY')\n","else:\n","  # If not colab, enter your key here, or use an environment variable.\n","  # (this is only an example key, use yours)\n","  key = \"Gx5en9cEVvaZnjhdaushddhuhhO4PsI32sgldAXj\"\n","\n","# OpenAI Secrets\n","if COLAB:\n","    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n","\n","# Install needed libraries in CoLab\n","if COLAB:\n","    !pip install langchain langchain_openai"]},{"cell_type":"markdown","metadata":{"id":"PMLHwV0hpO-a"},"source":["# Assignment Submit Function\n","\n","You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems.\n","\n","**It is unlikely that should need to modify this function.**"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"ozSyLCNtpO-a","executionInfo":{"status":"ok","timestamp":1739235730922,"user_tz":360,"elapsed":100,"user":{"displayName":"Luv Letter","userId":"00690244338853962621"}}},"outputs":[],"source":["import base64\n","import os\n","import numpy as np\n","import pandas as pd\n","import requests\n","import PIL\n","import PIL.Image\n","import io\n","from typing import List, Union\n","\n","# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n","# submission counts.  The paramaters are as follows:\n","# data - List of pandas dataframes or images.\n","# key - Your student key that was emailed to you.\n","# course - The course that you are in, currently t81-558 or t81-559.\n","# no - The assignment class number, should be 1 through 10.\n","# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.\n","# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n","\n","def submit(\n","    data: List[Union[pd.DataFrame, PIL.Image.Image]],\n","    key: str,\n","    course: str,\n","    no: int,\n","    source_file: str = None\n",") -> None:\n","    if source_file is None and '__file__' not in globals():\n","        raise Exception(\"Must specify a filename when in a Jupyter notebook.\")\n","    if source_file is None:\n","        source_file = __file__\n","\n","    suffix = f'_class{no}'\n","    if suffix not in source_file:\n","        raise Exception(f\"{suffix} must be part of the filename.\")\n","\n","    ext = os.path.splitext(source_file)[-1].lower()\n","    if ext not in ['.ipynb', '.py']:\n","        raise Exception(f\"Source file is {ext}; must be .py or .ipynb\")\n","\n","    with open(source_file, \"rb\") as file:\n","        encoded_python = base64.b64encode(file.read()).decode('ascii')\n","\n","    payload = []\n","    for item in data:\n","        if isinstance(item, PIL.Image.Image):\n","            buffered = io.BytesIO()\n","            item.save(buffered, format=\"PNG\")\n","            payload.append({'PNG': base64.b64encode(buffered.getvalue()).decode('ascii')})\n","        elif isinstance(item, pd.DataFrame):\n","            payload.append({'CSV': base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n","        else:\n","            raise ValueError(f\"Unsupported data type: {type(item)}\")\n","\n","    response = requests.post(\n","        \"https://api.heatonresearch.com/wu/submit\",\n","        headers={'x-api-key': key},\n","        json={\n","            'payload': payload,\n","            'assignment': no,\n","            'course': course,\n","            'ext': ext,\n","            'py': encoded_python\n","        }\n","    )\n","\n","    if response.status_code == 200:\n","        print(f\"Success: {response.text}\")\n","    else:\n","        print(f\"Failure: {response.text}\")"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"H7kgvLHspO-a","jupyter":{"outputs_hidden":true}},"source":["# Assignment #4 Sample Code\n","\n","The following code provides a starting point for this assignment."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"8ZPLGWgkpO-a","colab":{"base_uri":"https://localhost:8080/","height":622},"executionInfo":{"status":"ok","timestamp":1739235779303,"user_tz":360,"elapsed":31628,"user":{"displayName":"Luv Letter","userId":"00690244338853962621"}},"outputId":"bf42dd2c-67fc-49e0-b7ff-373732c2e2f0"},"outputs":[{"output_type":"display_data","data":{"text/plain":["   target                                           response\n","0   chat1                      Hello John, nice to meet you!\n","1   chat2                      Hello Jane, nice to meet you!\n","2   chat1  That's a lovely choice, blue is often associat...\n","3  chat2                     That's a cheerful choice, Jane!\n","4   chat1  Your name is John, and your favorite color is ...\n","5   chat2                                 Your name is Jane."],"text/html":["\n","  <div id=\"df-95dd8ab4-fe61-448c-9306-6fc831e0a874\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>response</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>chat1</td>\n","      <td>Hello John, nice to meet you!</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>chat2</td>\n","      <td>Hello Jane, nice to meet you!</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>chat1</td>\n","      <td>That's a lovely choice, blue is often associat...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>chat2</td>\n","      <td>That's a cheerful choice, Jane!</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>chat1</td>\n","      <td>Your name is John, and your favorite color is ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>chat2</td>\n","      <td>Your name is Jane.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95dd8ab4-fe61-448c-9306-6fc831e0a874')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-95dd8ab4-fe61-448c-9306-6fc831e0a874 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-95dd8ab4-fe61-448c-9306-6fc831e0a874');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-979dea9e-96ab-4b25-a0f0-8429dbc8833e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-979dea9e-96ab-4b25-a0f0-8429dbc8833e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-979dea9e-96ab-4b25-a0f0-8429dbc8833e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_904c9a58-2d36-44fc-9eb2-8caea23476a7\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('output_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_904c9a58-2d36-44fc-9eb2-8caea23476a7 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('output_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"output_df","summary":"{\n  \"name\": \"output_df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"chat1\",\n          \"chat2\",\n          \"chat2 \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Hello John, nice to meet you!\",\n          \"Hello Jane, nice to meet you!\",\n          \"Your name is Jane.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Submitting assignment with:\n","  - Source file: /content/drive/My Drive/Colab Notebooks/assignment_SongyuhaoShi_t81_559_class4.ipynb\n","  - Submission Key: T2MzALQuoZ9883H7q4dzD6MkIHbvbZoh8zx462Nx\n","  - Course: 't81-559'\n","  - First few rows of submission data:\n","   target                                           response\n","0   chat1                      Hello John, nice to meet you!\n","1   chat2                      Hello Jane, nice to meet you!\n","2   chat1  That's a lovely choice, blue is often associat...\n","3  chat2                     That's a cheerful choice, Jane!\n","4   chat1  Your name is John, and your favorite color is ...\n","Success: Submitted Assignment 4 (t81-559) for s.songyuhao:\n","This is your first submission of this assignment.\n","Based on the provided information, here's the evaluation of the STUDENT CODE and STUDENT CSV DATA:\n","Item 1: Yes. The STUDENT CSV DATA has 6 lines, which matches the number of lines in the PROVIDED CSV INPUT and EXPECTED CSV OUTPUT.\n","Item 2: Yes. The STUDENT CSV DATA includes both the target and response columns.\n","Item 3: Yes. The PROVIDED CSV INPUT could have generated the outputs in STUDENT CSV DATA. The responses are appropriate for the given prompts and maintain consistency with the information provided in the input.\n","Item 4: Yes. The STUDENT CODE looks correct to produce output similar to the EXPECTED CSV OUTPUT. It uses the appropriate libraries, sets up chatbots for each conversation, processes the input data, and generates responses using a language model.\n","Item 5: Yes. The STUDENT CSV DATA is close enough to the EXPECTED CSV OUTPUT in meaning. While the exact wording differs slightly, the responses convey the same information and maintain a similar tone and structure.\n","You addressed all items (5/5).\n","No warnings or errors (only notes), you will probably do well, but no guarantee. :-)\n"]}],"source":["import os\n","import pandas as pd\n","import pickle\n","from langchain.chains import ConversationChain\n","from langchain.memory import ConversationSummaryMemory\n","from langchain_openai import ChatOpenAI\n","from langchain_core.prompts.chat import PromptTemplate\n","from IPython.display import display  # Standard Colab display\n","\n","# ✅ Ensure OpenAI API Key is set\n","if \"OPENAI_API_KEY\" not in os.environ:\n","    raise ValueError(\"Please set your OpenAI API Key in Colab: os.environ['OPENAI_API_KEY'] = 'your_OPENAI_API_KEY'\")\n","\n","# ✅ Define the source file for submission\n","file = \"/content/drive/My Drive/Colab Notebooks/assignment_SongyuhaoShi_t81_559_class4.ipynb\"\n","\n","# ✅ Load conversation transcript\n","df = pd.read_csv(\"https://data.heatonresearch.com/data/t81-559/assignments/transcript4.csv\")\n","\n","# ✅ Define conversation template\n","DEFAULT_TEMPLATE = \"\"\"You are a helpful assistant. Format answers with text only.\n","Answer in a single sentence.\n","\n","Current conversation:\n","{history}\n","Human: {input}\n","AI:\"\"\"\n","\n","MODEL = 'gpt-4o-mini'  # ✅ Use OpenAI GPT-4o-mini model\n","\n","# ✅ Define ChatBot class\n","class ChatBot:\n","    def __init__(self, llm_chat, llm_summary, template):\n","        self.llm_chat = llm_chat\n","        self.llm_summary = llm_summary\n","        self.template = template\n","        self.prompt_template = PromptTemplate(input_variables=[\"history\", \"input\"], template=self.template)\n","\n","        # ✅ Initialize memory and conversation chain\n","        self.memory = ConversationSummaryMemory(llm=self.llm_summary)\n","        self.conversation = ConversationChain(\n","            prompt=self.prompt_template,\n","            llm=self.llm_chat,\n","            memory=self.memory,\n","            verbose=False\n","        )\n","\n","        self.history = []  # Store conversation history\n","\n","    def converse(self, prompt):\n","        \"\"\"Process user input and update memory\"\"\"\n","        self.history.append([self.memory.buffer, prompt])\n","        output = self.conversation.invoke(prompt)\n","        return output['response']\n","\n","    def chat(self, prompt):\n","        \"\"\"Process a single conversation input and return response\"\"\"\n","        return self.converse(prompt)\n","\n","    def save_history(self, file_path):\n","        \"\"\"Save conversation history\"\"\"\n","        with open(file_path, 'wb') as f:\n","            pickle.dump(self.history, f)\n","\n","    def load_history(self, file_path):\n","        \"\"\"Load conversation history\"\"\"\n","        with open(file_path, 'rb') as f:\n","            self.history = pickle.load(f)\n","            if self.history:\n","                self.memory.buffer = self.history[-1][0]\n","\n","# ✅ Initialize OpenAI LLM\n","llm_chat = ChatOpenAI(model_name=MODEL, temperature=0.7)\n","llm_summary = ChatOpenAI(model_name=MODEL, temperature=0.3)\n","\n","# ✅ Create two independent chatbots\n","chat1 = ChatBot(llm_chat, llm_summary, DEFAULT_TEMPLATE)\n","chat2 = ChatBot(llm_chat, llm_summary, DEFAULT_TEMPLATE)\n","\n","# ✅ Process conversations\n","responses = []\n","for _, row in df.iterrows():\n","    target, prompt = row[\"target\"], row[\"prompt\"]\n","    bot = chat1 if target == \"chat1\" else chat2  # Choose the corresponding chatbot\n","    response = bot.chat(prompt)\n","    responses.append({\"target\": target, \"response\": response})\n","\n","# ✅ Convert results to DataFrame\n","output_df = pd.DataFrame(responses)\n","\n","# ✅ Display results in Colab\n","display(output_df)\n","\n","# ✅ Save output as CSV\n","output_df.to_csv(\"chat_responses.csv\", index=False)\n","\n","# ✅ Prepare for submission\n","df_submit = output_df  # Assign final DataFrame to df_submit\n","key = \"T2MzALQuoZ9883H7q4dzD6MkIHbvbZoh8zx462Nx\"  # Replace with your actual key\n","\n","print(f\"Submitting assignment with:\")\n","print(f\"  - Source file: {file}\")\n","print(f\"  - Submission Key: {key}\")\n","print(f\"  - Course: 't81-559'\")\n","print(f\"  - First few rows of submission data:\")\n","print(df_submit.head())\n","\n","# ✅ Submit the assignment\n","submit(source_file=file, data=[df_submit], course='t81-559', key=key, no=4)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJpZKegdgq8Z"},"outputs":[],"source":["from langchain.chains import ConversationChain\n","from langchain.memory import ConversationSummaryMemory\n","from langchain_openai import ChatOpenAI\n","from langchain_core.prompts.chat import PromptTemplate\n","from IPython.display import display_markdown\n","import pickle\n","\n","DEFAULT_TEMPLATE = \"\"\"You are a helpful assistant. Format answers with text only.\n","Answer in a single sentence.\n","\n","Current conversation:\n","{history}\n","Human: {input}\n","AI:\"\"\"\n","\n","MODEL = 'gpt-4o-mini'\n","\n","class ChatBot:\n","    def __init__(self, llm_chat, llm_summary, template):\n","        \"\"\"\n","        Initializes the ChatBot with language models and a template for conversation.\n","\n","        :param llm_chat: A large language model for handling chat responses.\n","        :param llm_summary: A large language model for summarizing conversations.\n","        :param template: A string template defining the conversation structure.\n","        \"\"\"\n","        self.llm_chat = llm_chat\n","        self.llm_summary = llm_summary\n","        self.template = template\n","        self.prompt_template = PromptTemplate(input_variables=[\"history\", \"input\"], template=self.template)\n","\n","        # Initialize memory and conversation chain\n","        self.memory = ConversationSummaryMemory(llm=self.llm_summary)\n","        self.conversation = ConversationChain(\n","            prompt=self.prompt_template,\n","            llm=self.llm_chat,\n","            memory=self.memory,\n","            verbose=False\n","        )\n","\n","        self.history = []\n","\n","    def converse(self, prompt):\n","        \"\"\"\n","        Processes a conversation prompt and updates the internal history and memory.\n","\n","        :param prompt: The input prompt from the user.\n","        :return: The generated response from the language model.\n","        \"\"\"\n","        self.history.append([self.memory.buffer, prompt])\n","        output = self.conversation.invoke(prompt)\n","        return output['response']\n","\n","    def chat(self, prompt):\n","        \"\"\"\n","        Handles the full cycle of receiving a prompt, processing it, and displaying the result.\n","\n","        :param prompt: The input prompt from the user.\n","        \"\"\"\n","        print(f\"Human: {prompt}\")\n","        output = self.converse(prompt)\n","        display_markdown(output, raw=True)\n","\n","    def print_memory(self):\n","        \"\"\"\n","        Displays the current state of the conversation memory.\n","        \"\"\"\n","        print(\"**Memory:\")\n","        print(self.memory.buffer)\n","\n","    def clear_memory(self):\n","        \"\"\"\n","        Clears the conversation memory.\n","        \"\"\"\n","        self.memory.clear()\n","\n","    def undo(self):\n","        \"\"\"\n","        Reverts the conversation memory to the state before the last interaction.\n","        \"\"\"\n","        if len(self.history) > 0:\n","            self.memory.buffer = self.history.pop()[0]\n","        else:\n","            print(\"Nothing to undo.\")\n","\n","    def regenerate(self):\n","        \"\"\"\n","        Re-executes the last undone interaction, effectively redoing an undo operation.\n","        \"\"\"\n","        if len(self.history) > 0:\n","            self.memory.buffer, prompt = self.history.pop()\n","            self.chat(prompt)\n","        else:\n","            print(\"Nothing to regenerate.\")\n","\n","    def save_history(self, file_path):\n","        \"\"\"\n","        Saves the conversation history to a file using pickle.\n","\n","        :param file_path: The file path where the history should be saved.\n","        \"\"\"\n","        with open(file_path, 'wb') as f:\n","            pickle.dump(self.history, f)\n","\n","    def load_history(self, file_path):\n","        \"\"\"\n","        Loads the conversation history from a file using pickle.\n","\n","        :param file_path: The file path from which to load the history.\n","        \"\"\"\n","        with open(file_path, 'rb') as f:\n","            self.history = pickle.load(f)\n","            # Optionally reset the memory based on the last saved state\n","            if self.history:\n","                self.memory.buffer = self.history[-1][0]"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"_FiIkVPcpN25","colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"status":"error","timestamp":1739235261616,"user_tz":360,"elapsed":28,"user":{"displayName":"Luv Letter","userId":"00690244338853962621"}},"outputId":"efa0ee3f-0a71-4718-d4af-499afb7332e3"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'submit' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-f0e41379fb11>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Submit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_submit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcourse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m't81-559'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'submit' is not defined"]}],"source":["## ... continue your code...\n","\n","## Submit assignment\n","\n","# Submit\n","submit(source_file=file,data=[df_submit],course='t81-559',key=key,no=4)"]}],"metadata":{"anaconda-cloud":{},"colab":{"provenance":[{"file_id":"https://github.com/jeffheaton/app_generative_ai/blob/main/assignments/assignment_yourname_t81_559_class4.ipynb","timestamp":1739234427212}]},"kernelspec":{"display_name":"Python 3.11 (genai)","language":"python","name":"genai"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}